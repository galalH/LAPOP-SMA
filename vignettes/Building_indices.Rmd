---
title: "Building Indices"
output:
  rmarkdown::html_vignette:
    toc: yes
    fig_width: 8
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Building Indices}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      collapse = FALSE,
                      comment = "#>",
                      fig.align = "center")
#knitr::opts_chunk$set(fig.width = 8, fig.height = 6)
set.seed(1)
extrafont::loadfonts(quiet=TRUE)
options(scipen = 999) # turn-off scientific notation like 1e+48
library(unhcRstyle)
library(ggplot2)
library(mice)
library(plyr) 
library(GGally)
library(ggfortify)
library(stargazer)

```

## Introduction

An initial step in the analysis consist in the creation a series of indices to better understand different group of variables together.

Those indices can be built with principal component analyis and require the imputation of missing values.

We'll load all three 2014 datasets and construct a data frame containing the columns we want.

```{r}
mainDir <- getwd()
## If you save your analysis under vignette folder...
mainDirroot <- substring(mainDir, 0 , nchar(mainDir) - 10)


lapop.2014.GTM <- read.csv(paste0(mainDirroot, "/data-raw/lapop.2014.GTM.csv"))
lapop.2014.SLV <- read.csv(paste0(mainDirroot, "/data-raw/lapop.2014.SLV.csv"))
lapop.2014.HND <- read.csv(paste0(mainDirroot, "/data-raw/lapop.2014.HND.csv"))
```

## Authoritarianism index

This index will measure the a respondent's inclination toward authoritarian political attitudes. The following variables were measured in all three countries and correlate strongly with each other:

- `dem2`: Support for democracy or dictatorship (1=either is OK, 2=democracy, 3=dictatorship)
- `dem11`: Support for mano dura policies (1=iron fist, 2=broad participation)
- `jc10`: Coup is justified when crime is high (1=yes, 2=no)
- `jc13`: Coup is justified when corruption is high (1=yes, 2=no)
- `jc15a`: President justified in governing without legislature during crisis (1=yes, 2=no)



```{r}

v <- c('dem2','dem11','jc13','jc10','jc15a')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])
#dem2 has sort of an odd scale -- switch 1 and 2
my_data$dem2[my_data$dem2==1] <- 100
my_data$dem2[my_data$dem2==2] <- 1
my_data$dem2[my_data$dem2==100] <- 2
my_data <- my_data[,order(names(my_data))] # alphabetize columns
is.na(my_data[my_data>16]) <- TRUE
```



### Principal Componnent Analysis without imputation

```{r}
my_complete <- na.omit(my_data)

# Principal Components Analysis
pr_complete <- stats::prcomp(my_complete,center=TRUE,scale=FALSE)

##plot(pr_complete)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Authoritarianism index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```

41% of variance is concentrated in the first component.


### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))
```


```{r} 
ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

Most variables had fairly similar numbers of missing values; people were least willing to talk about expanded presidential powers (`jc15a`) and most willing to talk about mano dura policies (`dem11`).


What does PCA look like for one of the five imputed datasets?

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
#plot(pr[[1]])
autoplot(pr[[1]]) +
  labs(title = "Principal Componnent Analysis on Authoritarianism index", 
            subtitle = "With imputation ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) 


summary(pr[[1]])
```

PCA results look very similar to what we saw without imputation, which is good.

```{r, fig.width=10, fig.height=10}
# pc1 <- pr[[1]]$x[,1]
# pc2 <- pr[[1]]$x[,2]
# qplot(pc1,pc2) +  
#   labs(title = "Principal Componnent Analysis on Authoritarianism index", 
#             subtitle = "Without imputation ",
#             # x = " ", 
#             # y = "",
#              caption = "Latin American Public Opinion Project / Vanderbilt University") +
#           unhcRstyle::unhcr_theme() +
#           theme(axis.text = element_text(size = 6),
#                 legend.position = "none",
#                 panel.grid.major.x = element_line(color = "#cbcbcb"), 
#                 panel.grid.major.y = element_blank()) 
```

### Scatterplot matrix    

The distribution of PC1 seems to fall into three bands, suggesting that the index is dominated by one variable that takes on three values.

All of our imputations are really well-correlated, and the lowest-valued band is the most heavily-populated one.

```{r, fig.width=10, fig.height=10}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))

names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')

# make sure all correlations are positive
for (i in 2:ncol(all_pc1)) {  
  if (cor(all_pc1[,1],all_pc1[,2]) < 0) {
    all_pc1[,2] <- -1 * all_pc1[,2]
  }
}

ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

### Influence of indicator    

```{r, fig.width=10, fig.height=5}
all_pc1$avg <- rowMeans(all_pc1)
q25 <- quantile(all_pc1$avg)[2]
q75 <- quantile(all_pc1$avg)[4]
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg <= q25,],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg >= q75,],na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(qchange$hi)

ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=(qchange$even+qchange$hi)/2,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.2)) +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
  # theme_classic() +
  # theme(legend.position='none',
  #       axis.ticks=element_blank(),
  #       axis.line=element_blank(),
  #       axis.text.x=element_blank(),
  #       axis.title=element_blank(),
  #       text=element_text(size=20))
```

Compared to the lowest quantile, the highest quantile of our proposed index has much higher values for `dem2` and decreasing values for everything else. Lower values for `dem2` indicate a preference for democracy, while higher values of the binary variables indicate less-authoritarian attitudes. The scale is therefore in pointing in the right direction.

`dem2` is the only variable that takes on three values; its strong slope in this plot suggests that it is the dominant factor in our index.



```{r}
# Let's normalize and average PC1:
all_pc1$norm <- scale(all_pc1$avg)
```



```{r,warning=FALSE}
predict_data <- data.frame(dem2=c(1,3),dem11=c(2,1),jc13=c(2,1),
                          jc10=c(2,1),jc15a=c(2,1))
# The first row of predict_data should be the least-authoritarian response
# possible, while the second is the most-authoritarian.
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax-mean(all_pc1$avg)) / sd(all_pc1$avg)
# should match quantile(all_pc1$norm)
predict_data2 <- data.frame(2-diag(5))
names(predict_data2) <- names(my_data)
predict_data2[,'dem2'] <- 3 - predict_data2[,'dem2']
scores <- rowMeans(sapply(1:5, function(i) 
  predict(pr[[i]],predict_data2)[,1]))
scores <- (scores-mean(all_pc1$avg)) / sd(all_pc1$avg)
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))


ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

While all five variables have an impact on the composite index, `dem2` has by far the strongest influence.

We can be more rigorous about this by calculating p-values. We'll have to do this differently for `dem2` (which takes on three values) than for the ones that only take on two.  All are significantly-correlated (especially `dem2`).


```{r}
bin_cor <- function(var2) {
  # Determine the correlation between all_pc1$norm and a binary variable 
  # var2. This uses a Fisher test conditioned on the values of var2.
  tmp <- data.frame(v1=all_pc1$norm,v2=my_data[,var2])
  tmp$v2 <- tmp$v2 - min(tmp$v2,na.rm=TRUE) # convert to 0-1 scale
  if (sum(tmp$v2==0,na.rm=TRUE) > 1 & sum(tmp$v2==1,na.rm=TRUE) > 1) {
    tt <- t.test(tmp$v1[tmp$v2==0],tmp$v1[tmp$v2==1])
    res=data.frame(var=var2,est=tt$estimate[2]-tt$estimate[1],pval=tt$p.value,
                 stringsAsFactors=FALSE)
  }
  res
}

my_data$dem2_lo <- as.numeric(my_data$dem2 >= 2)
my_data$dem2_hi <- as.numeric(my_data$dem2 > 2)
bin_vars <- c('dem2_lo','dem2_hi','dem11','jc13','jc10','jc15a')
ldply(bin_vars,bin_cor)
```



```{r}
#Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:
#quantile(all_pc1$norm)
```

## Sympathy with government critics index

This index measures a respondent's level of sympathy with government critics (aka a measure of political tolerance). It includes the following variables:

- `d1`: Approval of government critics' right to vote (1=low, 10=high)
- `d2`: Approval of government critics' right to hold peaceful demonstrations
- `d3`: Approval of government critics' right to run for office
- `d4`: Approval of government critics' right to make speeches
- `e5`: Approval of participation in legal demonstrations (1=disapprove, 10=approve)
- `e15`: Approval of blocking roads during protest (1=approve, 10=disapprove)
- `e3`: Approval of groups attempting to overthrow government (1=disapprove, 10=approve)
- `e16`: Approval of vigilante justice (1=disapprove, 10=approve)



```{r}

v <- c('d1','d2','d3','d4','e5','e15','e3','e16')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])
my_data <- my_data[,order(names(my_data))] # alphabetize columns
is.na(my_data[my_data>16]) <- TRUE
```



### Principal Componnent Analysis without imputation

```{r}
my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete,center=TRUE,scale=FALSE)
##plot(pr_complete)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Sympathy with government critics index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```

38% of variance is in the first principal component -- pretty typical for our composite indices.

### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

None of these involved a lot of imputation; in general the questions about the political rights of government critics (`d1`,`d2`,`d3`,`d4`) needed more imputation than the questions about the appropriateness of protests or anti-government activity. 

Look at PCA for one of our imputed datasets:

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))#plot(pr[[1]])
autoplot(pr[[1]]) +
  labs(title = "Principal Componnent Analysis on Sympathy with Government critics index", 
            subtitle = "With imputation ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) 
summary(pr[[1]])
```

PCA results look very similar to what we saw without imputation, which is good.

```{r, fig.width=10, fig.height=10}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2) + theme_classic()
```


### Scatterplot matrix   

This scatterplot shows a very continuous distribution along PC1; a good sign that a single variable doesn't really dominate this index. It helps that each variable can take a large number of values, meaning that a large number of combinations are possible (and present).

```{r, fig.width=10, fig.height=10}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All of our imputations are really well-correlated, and the distributions of PC1 look well-behaved.


### Influence of indicator  

```{r, fig.width=10, fig.height=5}
all_pc1$avg <- rowMeans(all_pc1)
q25 <- quantile(all_pc1$avg)[2]
q75 <- quantile(all_pc1$avg)[4]
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg <= q25,],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg >= q75,],na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(qchange$hi)


ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=(qchange$even+qchange$hi)/2,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables increase with PC1 -- high values indicate greater approval of dissident rights, so our index is pointing in the right direction. The steepest slope (i.e. the largest difference between the lowest and highest quartiles) belongs to `d2` (approval of critics' right to hold peaceful demonstrations), while `e3` (approval of groups trying to overthrow the government) has the shallowest slope. Even the most tolerant people don't have much patience with revolutionaries.

Let's normalize and average PC1:

```{r}
all_pc1$norm <- scale(all_pc1$avg)
```

Now, let's see how each variable contributes to the composite score:

```{r,warning=FALSE}
predict_data <- data.frame(d1=c(1,10),d2=c(1,10),d3=c(1,10),d4=c(1,10),
                           e5=c(1,10),e15=c(1,10),e3=c(1,10),e16=c(1,10))
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax-mean(all_pc1$avg)) / sd(all_pc1$avg)

predict_data2 <- data.frame(diag(8)+1)
names(predict_data2) <- names(my_data)
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (scores-mean(all_pc1$avg)) / sd(all_pc1$avg)
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))

ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

This is roughly what we'd expect -- all variables have an influence, with `d2` the strongest and `e3` the weakest.

We can be more rigorous about this by calculating p-values. As all variables are measured on a 1-10 scale, we can do this using linear regression.

```{r}
lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
sapply(c('d1','d2','d3','d4','e3','e5','e15','e16'),
       function(x) lmp(lm(all_pc1$norm ~ my_data[,x])))
```

All are extremely significant.

We'll visualize `e16` (approval of vigilante justice); modify the code below if you want to look at the others:

```{r}
e16 <- data.frame(q=my_data$e16,w=all_pc1$norm)
e16 <- na.omit(e16)
my_lm <- lm(data=e16, q ~ w)
summary(my_lm)
ggplot(e16,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('e16') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

The correlation is far from perfect, but people with a high value of our index are significantly more likely to appove of vigilante justice. It's interesting that `e16` seems fairly polarized, with a lot of people answering either 1 or 10.

Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:

```{r}
quantile(all_pc1$norm)
```


## Community Activity index 

* `cp5`: Tried to solve a community problem (1=Once a week, 2=Once or twice a month, 3=Once or twice a year, 4=Never)
* `cp7`: Attended meetings of Parent Association (1=Once a week, 2=Once or twice a month, 3=Once or twice a year, 4=Never)
* `cp8`: Attended meetings of Community Improvement Association (1=Once a week, 2=Once or twice a month, 3=Once or twice a year, 4=Never)
* `cp13`: Attended meetings of a Political Party (1=Once a week, 2=Once or twice a month, 3=Once or twice a year, 4=Never)
* `cp20`: Attended meetings of Women's Group (1=Once a week, 2=Once or twice a month, 3=Once or twice a year, 4=Never)



```{r}
 
v <- c('cp5','cp7','cp8','cp13','cp20')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])
is.na(my_data[my_data>16]) <- TRUE
my_data <- my_data[,order(names(my_data))] # alphabetize columns
```


### Principal Componnent Analysis without imputation

```{r}
my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete,center=TRUE,scale=FALSE)
##plot(pr_complete)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Sympathy with government critics index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```
Without any imputation, 38.4% of variance is concentrated on the first principal component.


### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

None of the variables stand out as needing too much imputation, with the CLEAR exception of `cp20`, which was question conditioned on the subject being female. 

Presumably, what the imputation is telling us is that the individual in question would go to women's groups if men were invited.

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
plot(pr[[1]])
summary(pr[[1]])
```

With the imputation, we don't have much change; 37% of variance is concentrated on the first principal component.

```{r}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2) + theme_classic()
```


### Scatterplot matrix   

Variation along PC1 seems to be fairly continuous, indicating that this index isn't dominated by a single variable.

```{r}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

Our different imputed datasets correlate strongly, and the distribution skews toward low values of PC1.


### Influence of indicator  

```{r, fig.height=5, fig.width=10}
all_pc1$avg <- rowMeans(all_pc1)
q25 <- quantile(all_pc1$avg)[2]
q75 <- quantile(all_pc1$avg)[4]
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg <= q25,],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg >= q75,],na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(qchange$hi)
ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=qchange$hi,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All five variables decrease as the index increases; recall that larger values correspond to less-frequent participation, so our index is pointing in the right direction. Because `cp7` (parent's association attendance) has the steepest slope, we suspect that it will have the strongest influence on the composite index.

```{r}
all_pc1$norm <- scale(all_pc1$avg) 
predict_data <- data.frame(cp5=c(4,1),cp7=c(4,1),cp8=c(4,1),
                           cp13=c(4,1),cp20=c(4,1))
# The first row is the responses that would come from the least-engaged person
# possible; the second row is the responses from a maximally-engaged person.
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax - mean(all_pc1$avg)) / sd(all_pc1$avg) 
# Comparing minmax to quantile(all_pc1$norm), we can see that some people are
# pretty close to the minimum level of engagement, and no one is near the 
# maximum.

predict_data2 <- data.frame(4-diag(5))
names(predict_data2) <- names(my_data)
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (scores-mean(all_pc1$avg)) / sd(all_pc1$avg) 
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))

ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables influence the index; the weakest influence comes from `cp13` (Attended meetings of a political party), apparently because even the most-engaged quartile hardly did this at all.

Since all variables take on multiple values, we will check p-values using linear regression.

```{r}
lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
sapply(c('cp5','cp7','cp8','cp13','cp20'),
       function(x) lmp(lm(all_pc1$norm ~ my_data[,x])))
```

All p-values are highly-significant.

```{r}
cp7 <- data.frame(q=my_data$cp7,w=all_pc1$norm)
cp7 <- na.omit(cp7)
my_lm <- lm(data=cp7, q ~ w)
summary(my_lm)
ggplot(cp7,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('cp7') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

```{r}
cp13 <- data.frame(q=my_data$cp13,w=all_pc1$norm)
cp13 <- na.omit(cp13)
my_lm <- lm(data=cp13, q ~ w)
summary(my_lm)
ggplot(cp13,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('cp13') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

```{r}
cp20 <- data.frame(q=my_data$cp20,w=all_pc1$norm)
cp20 <- na.omit(cp20)
my_lm <- lm(data=cp20, q ~ w)
summary(my_lm)
ggplot(cp20,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('cp20') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:

```{r}
quantile(all_pc1$norm)
```

## Fear index


The following variables related to fear and violence :

- `fear10`: Has avoided walking through dangerous areas
- `vic44`: Organized in Neighborhood for Security (0 = no, 1=yes) 
- `vic1exta`: Victim of Crime (Frequency) (999999 if vic1ext=2, otherwise max=15) 
- `vic1hogar`: Other Victim of Crime in Household (1=yes, 2=no)
- `aoj11`: Perception of Neighborhood Security (1 = safe, 4 = unsafe) 
- `pese1`: Perception of Neighborhood Violence (1=high, 3=low) 
- `pese2`: Trend in Neighborhood Violence (1=high, 3=low) 
- `aoj17`: Gang Presence in Neighborhood (1 = a lot, 4 = none) 
- `diso7`: Youth Loitering a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso8`: Youth in Gangs a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso10`: Illegal Drug Trafficking a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso18`: Gang Fights a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso14`: Drug Addicts a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso16`: Assaults a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `diso17`: Shootings a Problem in the Neighborhood (1 = very serious, 5 = not a problem) 
- `vicbar1`: Burglaries in the Neighborhood (1=yes, 2=no) 
- `vicbar1f`: Number of Occurrences of Burglaries in Neighborhood (1 = weekly, 3=yearly) 
- `vicbar3`: Sales of Illegal Drugs in Neighborhood (1=yes, 2=no) 
- vicbar4: Extortion or Blackmail in the Neighborhood (1=yes, 2=no)
- `vicbar7`: Murders in the Neighborhood (1=yes, 2=no) 
- `a4` == 5,14,27,30,57: Biggest problem related to crime/violence/security


`vic44` appears to be on-topic, but actually doesn't correlate as strongly as the other variables do, so we're leaving it out.


### Principal Componnent Analysis without imputation

```{r,message=FALSE}
 
v <- c('fear10','vic1ext','vic1exta','vic1hogar','aoj11','pese1','pese2',
       'aoj17','diso7','diso8','diso10','diso18','diso14','diso16','diso17',
       'vicbar1','vicbar1f','vicbar3','vicbar4','vicbar7','a4')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])

#my_data[my_data$vic1exta > 800000,'vic1exta'] <- 0

my_data$a4 <- as.numeric(my_data$a4 %in% c(5,14,27,30,57))

is.na(my_data[my_data>800000]) <- TRUE

my_data <- my_data[,order(names(my_data))] # alphabetize columns

my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete, center = TRUE, scale = FALSE)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Fear index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```

41.3% of total variance winds up in the first component.
### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

The only variable that needed a lot of imputation was `vicbar1f` -- the number of burglaries in the neighborhood. I'm guessing this is because people don't always know about all the burglaries that might be going on. Let's look at the PCA for one of our imputed datasets.

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
plot(pr[[1]])
#summary(pr[[1]])
```

Imputation decreased the fraction of variance in the first component to 46.7%.

```{r}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2) + theme_classic()
```


### Scatterplot matrix   

The distribution along PC1 looks pretty continuous, while the PC2 distribution looks very skewed. Fortunately, we're only using PC1.

```{r}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1', 'imp2', 'imp3', 'imp4', 'imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())

all_pc1$avg <- rowMeans(all_pc1)
```

Correlations are high, and the distribution is skewed toward high values.

### Influence of indicator  

```{r,fig.height=8,fig.width=10}
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg < quantile(all_pc1$avg)[2],],
                                   na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg > quantile(all_pc1$avg)[4],],
                                  na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(qchange$hi)
ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=(qchange$even+qchange$hi)/2,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

The `diso` variables all increase dramatically, while `aoj11` shows a dramatic decrease. This suggests that high values of the index indicate not being particularly concerned about crime and violence; we'll have to reverse the scale.

```{r}
all_pc1$norm <- scale(-all_pc1$avg) # sign flip -- now high values mean more fear
predict_data <- data.frame(fear10 = c(0,1), vic1ext = c(2,1),
                           vic1exta=c(0,max(my_data$vic1exta)),
                           vic1hogar=c(2,1),aoj11=c(1,4),pese1=c(3,1),
                           pese2=c(3,1),aoj17=c(4,1),diso7=c(5,1),diso8=c(5,1),
                           diso10=c(5,1),diso18=c(5,1),diso14=c(5,1),
                           diso16=c(5,1),diso17=c(5,1),vicbar1=c(2,1),
                           vicbar1f=c(3,1),vicbar3=c(2,1),vicbar4=c(2,1),
                           vicbar7=c(2,1),a4=c(0,1))

minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (mean(all_pc1$avg) - minmax) / sd(all_pc1$avg)
# quantile(all_pc1$norm)
fear <- data.frame(w=all_pc1$norm) 
```

```{r}
predict_data2 <- data.frame(diag(21))
names(predict_data2) <- names(predict_data)
# right now, you have something that would feed 0's and 1's into your score
# prediction -- this doesn't really make sense because many of your questions
# are on a scale from 1-2 or 1-4. Here's one (slightly clunky) way to fix it:
predict_data2$fear10 <- 4 - 3*predict_data2$fear10 
predict_data2$vic1ext <- 2 - predict_data2$vic1ext
predict_data2$vic1exta <- 20*predict_data2$vic1exta
predict_data2$vic1hogar <- 2 - predict_data2$vic1hogar
predict_data2$aoj11 <- 1 + 3*predict_data2$aoj11
predict_data2$aoj17 <- 4 - 3*predict_data2$aoj17
predict_data2$pese1 <- 3 - 2*predict_data2$pese1
predict_data2$pese2 <- 3 - 2*predict_data2$pese2
predict_data2$diso7 <- 5 - 4*predict_data2$diso7
predict_data2$diso8 <- 5 - 4*predict_data2$diso8
predict_data2$diso10 <- 5 - 4*predict_data2$diso10
predict_data2$diso18 <- 5 - 4*predict_data2$diso18
predict_data2$diso14 <- 5 - 4*predict_data2$diso14
predict_data2$diso16 <- 5 - 4*predict_data2$diso16
predict_data2$diso17 <- 5 - 4*predict_data2$diso17
predict_data2$vicbar1 <- 2 - predict_data2$vicbar1
predict_data2$vicbar1f <- 3 - 2*predict_data2$vicbar1f
predict_data2$vicbar3 <- 2 - predict_data2$vicbar3
predict_data2$vicbar4 <- 2 - predict_data2$vicbar4
predict_data2$vicbar7 <- 2 - predict_data2$vicbar7
```

Now, in each row of predict_data2, all values are those that will give a lower score, except for one.

```{r}
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (mean(all_pc1$avg)-scores)/sd(all_pc1$avg)
```

Now you can see that all of the scores are reasonably close to the minimum value stored in minmax.
```{r}
diff <- data.frame(d=(scores-minmax[1]), n = names(predict_data))

ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables seem to have an effect, with a somewhat smaller one for `fear10` (avoided walking through dangerous areas), and larger ones for the `diso` variables and `vic1exta` (frequency of victimization)

```{r,warning=FALSE,message=FALSE}
fear10 <- data.frame(q=my_data$fear10,w=fear$w)
fear10 <- na.omit(fear10)
my_lm <- lm(data=fear10, q ~ w)
ggplot(fear10,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
  size=10,x=-1.5,y=1,hjust=0,vjust=0,color='royalblue') +
  ylab('fear10') +
  xlab('Fear index') +
  theme(text=element_text(size=20))
```


```{r}
lmp <- function (modelobject) {
  if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
lm_data <- my_data[,c('vic1exta','aoj11','aoj17','pese1','pese2',
                      'diso7','diso8','diso10','diso14','diso16','diso17',
                      'diso18','vicbar3')]
#sapply(lm_data, function(x) lmp(lm(x ~ all_pc1$norm)))
```


```{r}
bin_cor <- function(var) {
  tt <- t.test(all_pc1$norm[var==min(var,na.rm=TRUE)],
               all_pc1$norm[var==max(var,na.rm=TRUE)])
  tt$p.value
}
```


```{r}
bin_vars <- c('fear10','vic1ext','vic1hogar','vicbar1','vicbar3',
              'vicbar4','vicbar7')
#sapply(bin_vars,function(x) bin_cor(my_data[,x]))
```

Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:

```{r}
quantile(all_pc1$norm)
```


```{r,message=FALSE}
set.seed(12345) # for reproducibility

incl <- c('vic44','fear10','vic1ext',
         'vic1exta','vic1hogar','aoj11','pese1','pese2','aoj17','diso7',
         'diso8','diso10','diso18','diso14','diso16','diso17','vicbar1', 
         'vicbar1f','vicbar3','vicbar4','vicbar7')

hnd_data <- lapop.2014.HND[,incl]
slv_data <- lapop.2014.SLV[,incl]
gtm_data <- lapop.2014.GTM[,incl]
my_data <- rbind(gtm_data,hnd_data,slv_data)

my_data$vic1exta[my_data$vic1exta == 999999] <- 0
is.na(my_data[my_data>30]) <- TRUE

my_imp <- mice(my_data, printFlag = F)
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))

all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1', 'imp2', 'imp3', 'imp4', 'imp5')
all_pc1$imp1 <- -all_pc1$imp1
all_pc1$imp4 <- -all_pc1$imp4
all_pc1$avg <- rowMeans(all_pc1)
all_pc1$norm <- scale(-all_pc1$avg) # sign flip -- now high values mean more fear
```

Let's see how people's level of fear correlates with their answers to `a4` -- the most serious problem facing the country. This is a little tricky, since the coding is consistent between countries (e.g. `a4=4` means poverty everywhere), but not all of the possible answers were on the questionnaire for any given country. If any country-specific answers turn out to be significant, we'll have to make sure they're significant at a country level as well.

```{r}
fear <- data.frame(w=all_pc1$norm)
a4 <- c(lapop.2014.HND$a4,lapop.2014.SLV$a4,lapop.2014.GTM$a4)
a4[a4==888888] <- NA
a4[a4==988888] <- NA
fear$a4 <- a4

categ_unsorted <- function(f,x,categ) {
  # For a data from f with a continuous variable 'x' and an unsorted 
  # categorical variable 'categ', test whether the value of x is 
  # significantly higher or lower for each value of categ than for the
  # rest of the population. Do this using a two-sample t-test.
  result <- data.frame(var=character(),val=integer(),pval=double(),
                       mean=double(),othermean=double())
  for(q in unique(na.omit(f[,categ]))) {
    if(sum(f[,categ]==q,na.rm=TRUE) > 1) {
      yes <- fear[fear[,categ]==q,x]
      no <- fear[fear[,categ]!=q,x]
      tt <- t.test(yes,no,na.rm=TRUE)
      newrow <- data.frame(var=categ,val=q,pval=tt$p.value,
                       mean=tt$estimate[[1]],
                       othermean=tt$estimate[[2]])
      result <- rbind(result,newrow)
    }
  }
  result
}

categ_unsorted(fear,'w','a4')
```

So it looks like the only strong correlation here is that people who are concerned about human rights violations are significantly *less* fearful than the rest of the population. 

Another unordered categorical variable would be `for1n` (Country with the most influence in the region).

```{r}
for1n <- c(lapop.2014.HND$for1n,lapop.2014.SLV$for1n,lapop.2014.GTM$for1n)
for1n[for1n==888888] <- NA
for1n[for1n==988888] <- NA
fear$for1n <- for1n
categ_unsorted(fear,'w','for1n')
mean(for1n==4,na.rm=TRUE)
mean(for1n==2,na.rm=TRUE)
```

So the 71% of people who feel that the USA (`for1n=4`) is the most influential country in the region are significantly more fearful than the remaining 29%, while the 9% who think Japan has the most influence (`for1n==2`) are less fearful than the remaining 91%. Everything else turns out not to be significant. I don't really know what makes the people who perceive a high Japanese influence different from everyone else, but it's a pretty big difference.

## Transparency index


 *  `honqt1` : Transparency of the presidency of the republic (1 = very, 4 = not at all)
 *  `honqt2` : Transparency of the National Congress
 *  `honqt3` : Transparency of the Government Accountability Office
 *  `honqt4` : Transparency of the state enterprises (ENEE, SANAA, HONDUTEL etc.)
 *  `honqt5` : Transparency of the police
 *  `honqt6` : Transparency of the Armed Forces
 *  `honqt7` : Transparency of the Public Ministry
 *  `honqt8` : Transparency of the National Anticorruption Council
 *  `honqt9` : Transparency of the municipal government
 *  `honqt10` : Transparency of the Superior Court of Accounts
 *  `honqt11` : Transparency of the Institute for Access to Public Information
 *  `honqt12` : Transparency of the Supreme Electoral Tribunal


### Principal Componnent Analysis without imputation

```{r,message=FALSE}
 
my_data <- lapop.2014.HND[,paste('honqt',1:12,sep='')]
is.na(my_data[my_data>800000]) <- TRUE

my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete, center = TRUE, scale = FALSE)

##plot(pr_complete)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Transparency index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         

# save this to plot later
s <- summary(pr_complete)
df <- data.frame(t(s$importance))
names(df) <- c('stdev','proportion','cum')
df$pc <- 1:nrow(df)
```

52% of total variance winds up in the first component.

### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

None of the variables have more than 20% missing; most everyone has an opinion about the police (`honqt5`) and fewer have one about the Institute for Access to Public Information (`honqt11`).

Now calculate PCA for each of the imputed datasets.

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
s1 <- summary(pr[[1]])
df1 <- data.frame(t(s1$importance))
names(df1) <- c('stdev','proportion','cum')
df1$pc <- 1:nrow(df1)
df1$group <- 'after'
df$group <- 'before'
df1 <- rbind(df,df1)
ggplot(df1,aes(x=pc,y=cum,color=group)) +
  geom_point(size=5) +
  geom_line(size=2) +
  scale_y_continuous(limits=c(0,1)) +
  xlab('Principal component') +
  ylab('Cumulative variance') +
  annotate('text',x=2,y=df$cum[1],hjust=0,size=10,color='#2A3132',
           label=paste(round(df$cum[1]*100),'% variance in PC1',sep='')) +
  theme_classic() +
  theme(legend.title=element_blank(),
        axis.ticks=element_blank(),
        text=element_text(size=20))
```

Imputation decreased the fraction of variance in the first component slightly to 52% -- still pretty good.

```{r}
PC1 <- pr[[1]]$x[,1]
PC2 <- pr[[1]]$x[,2]
qplot(PC1,PC2) +
  theme_classic() +
  theme(legend.position='none',
        axis.ticks=element_blank(),
        axis.text=element_blank(),
        axis.line=element_blank(),
        text=element_text(size=20))
```



### Scatterplot matrix   

PC1 is a little bit "stripy", but still shows a decent distribution.

```{r}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1', 'imp2', 'imp3', 'imp4', 'imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

Correlations between imputed datasets are high; distributions look good.


### Influence of indicator  

```{r,fig.width=10,fig.height=5}
all_pc1$avg <- rowMeans(all_pc1)
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg < quantile(all_pc1$avg)[2],],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg > quantile(all_pc1$avg)[4],],na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(qchange$hi)
ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=(qchange$even+qchange$hi)/2,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=1.5,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=1.5,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5)) +
  scale_y_continuous(limits=c(1.5,3.8))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())

```

All values increase (toward less transparency) as the index increases -- need to flip sign below. 

```{r}
all_pc1$norm <- scale(-all_pc1$avg) # now high values mean more transparency
predict_data <- data.frame(honqt1=c(4,1))
for (i in 2:12) {
  predict_data[,paste('honqt',i,sep='')] <- predict_data$honqt1
}

minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (mean(all_pc1$avg) - minmax) / sd(all_pc1$avg)
#quantile(all_pc1$norm)
trans <- data.frame(w=all_pc1$norm) 
```

```{r}
predict_data2 <- data.frame(diag(ncol(predict_data)))
names(predict_data2) <- names(predict_data)
predict_data2 <- 4 - predict_data2
```

Now, in each row of predict_data2, all values are those that will give a lower score, except for one.

```{r}
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (mean(all_pc1$avg)-scores)/sd(all_pc1$avg)
```

Now you can see that all of the scores are reasonably close to the minimum value stored in minmax.
```{r}
diff <- data.frame(d=(scores-minmax[1]), n = names(predict_data))

ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables have a nearly equal effect.

```{r}
honqt5 <- data.frame(q=my_data$honqt5,w=trans$w)
my_lm <- lm(data=honqt5, q ~ w)
ggplot(honqt5,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
  size=10,x=-1.5,y=1,hjust=0,vjust=0,color='royalblue') +
  ylab('Transparency of police') +
  xlab('Transparency index') +
  theme(text=element_text(size=20))
```

```{r}
honqt11 <- data.frame(q=my_data$honqt11,w=trans$w)
my_lm <- lm(data=honqt11, q ~ w)
ggplot(honqt11,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
  size=10,x=0.5,y=4,hjust=0,vjust=0,color='royalblue') +
  ylab('Transparency of the IAPI') +
  xlab('Transparency index') +
  theme(text=element_text(size=20))
```

Test significance of correlations between the index and the component variables using linear regression.

```{r}
lmp <- function (modelobject) {
  if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
sapply(my_data, function(x) lmp(lm(x ~ all_pc1$norm)))
```

All are highly significant.

## Trust in Government Index 

The following is a proposal for a Trust in Government Index, for which the following variables were considered to be the most relevant in determining the citizens' trust in all civic, public, political and governmental structures. The following variables were measured in all three countries.

* `b1`: Courts Guarantee a Fair Trial (1=Not at all, 7=A lot)
* `b2`: Respect for Political Institutions (1=Not at all, 7=A lot)
* `b3`: Respect for Basic Rights (1=Not at all, 7=A lot)
* `b4`: Pride in Political System (1=Not at all, 7=A lot)
* `b6`: People Should Support the Political System (1=Not at all, 7=A lot)
* `b10a`: Trust in Judicial System (1=Not at all, 7=A lot)
* `b12`: Trust in Armed Forces (1=Not at all, 7=A lot)
* `b13`: Trust in National Legislature (1=Not at all, 7=A lot)
* `b18`: Trust in National Police (1=Not at all, 7=A lot)
* `b21`: Trust in Political Parties (1=Not at all, 7=A lot)
* `b21a`: Trust in Executive (1=Not at all, 7=A lot)
* `b32`: Trust in Local Government (1=Not at all, 7=A lot)
* `b47a`: Trust in Elections (1=Not at all, 7=A lot)
* `n9`: Evaluation of Administration's Handling of Corruption (1=Not at all, 7=A lot)
* `n11`: Evaluation of Administration's Handling of Citizen Security (1=Not at all, 7=A lot)
* `n15`: Evaluation of Administration's Handling of Economy (1=Not at all, 7=A lot)
* `b3milx`: Armed Forces Respect Human Rights (1=Not at all, 7=A lot)

```{r}
 
v <- c('b1','b2','b3','b4','b6','b10a','b12','b13','b18','b21','b21a','b32',
       'b47a','n9','n11','n15','b3milx')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])
my_data <- my_data[,order(names(my_data))] # alphabetize columns
is.na(my_data[my_data>16]) <- TRUE
```


### Principal Componnent Analysis without imputation

```{r}
my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete,center=TRUE,scale=FALSE)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Trust in government index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```

Without imputation, 40% of variance is concentrated in the first principal component.

### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

None of the variables stand out as needing really dramatic levels of imputation.

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
plot(pr[[1]])
summary(pr[[1]])
```

Following imputation, 39.8% of variance remained concentrated in the first principal component.

```{r}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2) + theme_classic()
```


### Scatterplot matrix   

The distribution along PC1 seems smooth, indicating that this isn't dominated by a single variable.

```{r}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

Correlations between imputations are high; distributions are well-behaved.


### Influence of indicator  

```{r,fig.height=5,fig.width=10}
all_pc1$avg <- rowMeans(all_pc1)
q25 <- quantile(all_pc1$avg)[2]
q75 <- quantile(all_pc1$avg)[4]
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg <= q25,],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg >= q75,],na.rm=TRUE))
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(c(qchange$low,qchange$hi))
ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=qchange$even,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables tend to increase with PC1; recall that higher values indicate more trust in government institutions. Our index is pointing in the right direction.

```{r}
all_pc1$norm <- scale(all_pc1$avg) 
predict_data <- data.frame(b1=c(1,7),b2=c(1,7),b3=c(1,7),b4=c(1,7),
                           b6=c(1,7),b10a=c(1,7),b12=c(1,7),
                           b13=c(1,7),b18=c(1,7),b21=c(1,7),b21a=c(1,7),
                           b32=c(1,7),b47a=c(1,7),n9=c(1,7), n11=c(1,7),  
                           n15=c(1,7),b3milx=c(1,7))
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax - mean(all_pc1$avg)) / sd(all_pc1$avg) 

predict_data2 <- data.frame(diag(17)+1)
names(predict_data2) <- names(my_data)
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (scores-mean(all_pc1$avg)) / sd(all_pc1$avg) 
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))

ggplot(diff,aes(x=reorder(n,d),
                y=d)) +
  geom_bar(stat='identity',fill=unhcr_blue) +
  coord_flip() + 
  labs(title = "How all variables contribute to the composite score?",
            subtitle = " ",
             x = " ",
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

All variables seem to have a significant impact on the score. Because all variables take on multiple values, we can obtain p-values froml linear regression.

```{r}
lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
sapply(c('b1','b2','b3', 'b4','b6','b10a','b12','b13',
                             'b18','b21','b21a','b32', 'b47a','n9','n11','n15', 'b3milx'),
       function(x) lmp(lm(all_pc1$norm ~ my_data[,x])))
```

All are highly significant.

```{r}
b2 <- data.frame(q=my_data$b2,w=all_pc1$norm)
b2 <- na.omit(b2)
my_lm <- lm(data=b2, q ~ w)
summary(my_lm)
ggplot(b2,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('b2') +
  xlab('Composite index') +
  theme(text=element_text(size=20))
```

Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:

```{r}
quantile(all_pc1$norm)
```


## Wealth index

A composite wealth index from Americas Barometer indicators can be built from the following:

- `r3`: Refrigerator in home (0 = No, 1 = Yes)
- `r4`: Landline in home
- `r4a`: Cell phone in home
- `r5`: Number of vehicles owned (0 = None, 1 = one, 2 = two, 3 = three or more)
- `r6`: Washing machine in home
- `r7`: Microwave oven in home
- `r8`: Owns motorcycle
- `r12`: Drinking water in home
- `r14`: Indoor bathroom in home
- `r15`: Computer in home
- `r18`: Internet access in home
- `r1`: Television in home
- `r16`: Flat-panel TV in home
- `r26`: Home connected to sewage system
- `q10new`: Monthly household income (scale of 0-16)
- `q10g`: Monthly personal income (scale of 0-16)


### Principal Componnent Analysis without imputation 

```{r}
 
v <- c('r3','r4','r4a','r5','r6','r7','r8','r12','r14','r15','r18','r1','r16',
       'r26','q10new','q10g')
my_data <- rbind(lapop.2014.GTM[,v],lapop.2014.SLV[,v],lapop.2014.HND[,v])
my_data <- my_data[,order(names(my_data))] # alphabetize columns
 
#We need to do something with missing values. It will be easier to work with them if we change them to NAs:
is.na(my_data[my_data>16]) <- TRUE
nrow(na.omit(my_data))
```

If we just ignore any rows with missing values, we'll end up with only 647 rows left -- 41% of what we started with. How many values are we missing, anyway?

```{r}
sum(is.na(my_data)) / (nrow(my_data)*ncol(my_data))
```

So we're only missing about 4% of values -- it hurts my heart to throw away 59% of the data because of that. It also might introduce biases (for example if poor or rich people are more likely to not answer questions). For now, though, I'll endure the pain and see what PCA looks like with just the complete data:

```{r}
my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete,center=TRUE,scale=FALSE)
## Better PCA plot with ggfortify
autoplot(pr_complete) +
  labs(title = "Principal Componnent Analysis on ", 
            subtitle = "Weatlh index ",
            # x = " ", 
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) #+### changing grid line that should appear) +
         
summary(pr_complete)
```

83% of the variance is in the first component, which is pretty good. Note that people typically recommend using `scale=TRUE`; the reason I didn't is because one of our variables (`r1`, TV in home) has a variance of zero in this dataset -- everyone counted said "yes". This gives us a divide-by-zero error when we scale, which is no good. 

We can look at a scatterplot of the first two principal components:

```{r,warning=FALSE}
qplot(pr_complete$x[,1],pr_complete$x[,2],xlim=c(-10,10),ylim=c(-10,10)) + 
  theme_classic()
```

These are the two principal components along which the variation is the most spread-out. The lattice-like pattern comes from the fact that we're seeing a projection of variables that can only take on certain discrete values, as opposed to continuous ones. In the ideal case, most of the variance would be in the first component, but this isn't too bad. If you want to see how some of the other dimenisions look, try changing the values 1 and 2 to others, up to 17 (which should contain the least variance).

Now let's try imputing those missing values.

There are a few different multiple imputation schemes available in R, but it's hard to find a good explanation of them. [This one](http://pj.freefaculty.org/guides/Rcourse/multipleImputation/multipleImputation-1-lecture.pdf) is OK, for being a really long powerpoint. I'll try doing this using the `mice` package (Multivariate Imputation by Chained Equations) and see how it does. More about MICE [here](http://www.stefvanbuuren.nl/mi/MICE.html).

### Missing values imputation

```{r}
my_imp <- mice(my_data, printFlag = F,seed=12345)
nmis <- my_imp$nmis
nm <- data.frame(nmis=nmis/nrow(my_data),var=names(nmis))

ggplot(nm,aes(x= reorder(var,nmis) ,
              y=nmis)) +
  geom_bar(stat = 'identity', fill = unhcRstyle::unhcr_blue) +
  coord_flip() +
  labs(title = "Fraction of imputed values", 
            # subtitle = " ",
             x = " ", 
             y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"), 
                panel.grid.major.y = element_blank()) +### changing grid line that should appear) +
        geom_hline(yintercept = 0, size = 0.7, colour = "#333333")
```

There's a lot going on in the output here. MICE generated 5 different imputed data sets, so that we can run the same analyses on each and see how they compare. Some columns have a lot more missing cells than others -- everybody knows whether they have a washing machine (`r6`), but flat-panel TVs (`r16`) caused some confusion, and a lot of people didn't disclose their personal income (`q10g`). The PredictorMatrix at the bottom shows which variables were used to predict others. Except for `r6` and `r15`, which didn't need predicting at all, it looks like everything was used to predict everything else. 

```{r}
v2 <- c('q10g','pais')
q10g <- rbind(lapop.2014.GTM[,v2],lapop.2014.SLV[,v2],lapop.2014.HND[,v2])
countries <- c('','Guatemala','El Salvador','Honduras')
q10g <- q10g[q10g$q10g > 800000,]
q10g$pais_text <- countries[q10g$pais]
table(q10g$pais_text)
```

Fortunately, non-responses to `q10g` came from the three countries in roughly equal fractions.

Here's an example from one row that had some missing values (`r1`, `r16`, and `q10g`):

```{r}
my_data[1,]
t(sapply(1:5,function(i) complete(my_imp,i)[1,]))
```

This family doesn't have much stuff and their income is low, but 3 of the 5 predictions gave them a flat-panel TV. These might not be reliable predictions. The personal income (`q10g`) varies between imputed datasets, but tends to be at the low end and is probably more trustworthy.

Now let's do the PCA calculation. We'll generate a structure called `pr` that
contains the results of 5 different PCA calculations for the 5 imputed datasets.
```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
```

We can visualize the fraction of variance contained in each of the 17 principal components to see to what extent variance is concentrated in the first few. (Do this for just the first imputed model.)

```{r}
plot(pr[[1]])
summary(pr[[1]])
```

About 85% of the total variance is concentrated in the first component, roughly the same as before imputation -- this means our imputation didn't mess things up too much (not yet, at least). What if we make a scatter plot of the first two components (for just one of the imputed datasets)?

```{r}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2) + theme_classic()
```


### Scatterplot matrix   

We want to be sure that all five of our imputed datasets are measuring the same thing. We can do this by plotting all of the pairwise scatterplots; R makes this easy for us, if we put them all in one data frame first.

```{r, fig.width=10, fig.height=10}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(all_pc1) +  
  labs(title = "Scatterplot matrix of data imputation  ",
            subtitle = "Scatterplots of each pair of numeric variable are drawn on the left part of the figure.\n Pearson correlation is displayed on the right.\n Variable distribution is available on the diagonal. ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

What is this showing? `imp1` through `imp5` are our five imputed datasets, and we're looking at the first principal component from each. On the diagonal of this matrix, we see distribution plots for each of them -- they all look really similar. Above the diagonal, we get pairwise correlations; for example `imp1` and `imp2` have a correlation of 0.912. All of these are fairly high. Below the diagonal, we see scatter plots for each pair of imputations. There are some disagreements, but in general they match up quite well. Averaging all five should help smooth out some of those cases where they disagree.


### Influence of indicator  

```{r,fig.height=5,fig.width=10}
all_pc1$avg <- rowMeans(all_pc1)
q25 <- quantile(all_pc1$avg)[2]
q75 <- quantile(all_pc1$avg)[4]
qchange <- data.frame(low=colMeans(my_data[all_pc1$avg <= q25,],na.rm=TRUE),
                      hi=colMeans(my_data[all_pc1$avg >= q75,],na.rm=TRUE))
qchange[c('q10new','q10g'),'low'] <- 0.1*qchange[c('q10new','q10g'),'low']
qchange[c('q10new','q10g'),'hi'] <- 0.1*qchange[c('q10new','q10g'),'hi']
qchange$slope <- qchange$hi - qchange$low
qchange$label <- rownames(qchange)
qchange$even <- rank(qchange$hi)/nrow(qchange)*max(c(qchange$low,qchange$hi))

ggplot(data=qchange) +
  geom_segment(aes(x=0,y=qchange$low,xend=1,yend=qchange$hi,
                   color=qchange$slope),size=1) +
  scale_color_gradient(low='#FF420E',high='#89DA59') +
  geom_text(aes(x=1,y=qchange$even,label=qchange$label,
                hjust=0,color=qchange$slope),size=5) +
  annotate("text",x=0,y=0,label='Average in lowest quartile',hjust=0) +
  annotate("text",x=1,y=0,label='Average in highest quartile',hjust=1) +
  scale_x_continuous(limits=c(0,1.5))  +
  labs(title = "Influence of Indicators per quartile",
            subtitle = " ",
            # x = " ",
            # y = "",
             caption = "Latin American Public Opinion Project / Vanderbilt University") +
          unhcRstyle::unhcr_theme() +
          theme(axis.text = element_text(size = 6),
                legend.position = "none",
                panel.grid.major.x = element_line(color = "#cbcbcb"),
                panel.grid.major.y = element_blank())
```

The `q10` variables increase dramatically from the lowest to the highest quartile, which makes sense as these are direct measures of income. The other variables all show more modest increases -- rich people own more things, but a household's assets are a function of more than just their income.

We can see more details about how the top and bottom quantiles differ. For example, nearly everyone in the top 25% has a refrigerator (`r3`), a cell phone (`r4a`), indoor drinking water (`r12`), and a television (`r1`), but motorcycles (`r8`) are pretty rare. In the bottom 25%, more people have cell phones (`r4a`) than indoor bathrooms (`r14`).

As another sanity check, let's look at the distribution of values from our composite index. First, we'll figure out what the hypothetical maximum and minimum values of the wealth index are, then we'll plot those together with the actual density distribution.

We'll adjust the score to have a mean of 0 and standard deviation of 1. The new value will be in a column called `norm`.

```{r}
all_pc1$norm <- scale(all_pc1$avg)
predict_data <- data.frame(r3=c(0,1),r4=c(0,1),r4a=c(0,1),r5=c(0,3),r6=c(0,1),
                           r7=c(0,1),r8=c(0,1),r12=c(0,1),r14=c(0,1),
                           r15=c(0,1),r18=c(0,1),r1=c(0,1),r16=c(0,1),
                           r26=c(0,1),q10new=c(0,16),q10g=c(0,16))
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax - mean(all_pc1$avg)) / sd(all_pc1$avg)
wealth <- data.frame(w=all_pc1$norm) 
ggplot(wealth,aes(x=w)) +
  geom_density(fill='bisque2',linetype='blank') +
  geom_segment(x=minmax[1],xend=minmax[1],y=0,yend=0.5,size=2,color='darkred') +
  geom_segment(x=mean(wealth$w),xend=mean(wealth$w),y=0,yend=0.5,size=2,color='bisque4') +
  geom_segment(x=minmax[2],xend=minmax[2],y=0,yend=0.5,size=2,color='darkolivegreen4') +
  annotate('text',label=paste("Lowest:",round(minmax[1],2)),  
           size=7,x=minmax[1]+0.05,y=0.4,hjust=0,vjust=0,color='darkred') +
  annotate('text',label="Mean: 0",  
           size=7,x=0.05,y=0.4,hjust=0,vjust=0,color='bisque4') +
  annotate('text',label=paste("Highest:",round(minmax[2],2)),  
           size=7,x=minmax[2]-0.05,y=0.4,hjust=1,vjust=0,color='darkolivegreen4') +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.line.y=element_blank()) 
```

Our data uses the full range of possible wealth values, and tends to be somewhat bunched up at the low end.

To understand our index better, we can ask how different types of responses contribute to it. In other words, how much does it add to someone's wealth index if they have a TV, or a motorcycle, or if their income increases by one level on the 16-point scale?

```{r,warning=FALSE}
predict_data2 <- data.frame(diag(16))
names(predict_data2) <- names(predict_data)
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (scores - mean(all_pc1$avg)) / sd(all_pc1$avg)
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))
diff_r <- diff[!diff$n %in% c('q10new','q10g'),]
diff_q <- diff[diff$n %in% c('q10new','q10g'),]
ggplot(diff_r,aes(x=n,y=d)) +
  geom_bar(stat='identity',fill='skyblue') +
  coord_flip() +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank())
```
```{r,fig.width=7,fig.height=2}
ggplot(diff_q,aes(x=n,y=d)) +
  geom_bar(stat='identity',fill='skyblue') +
  coord_flip() +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank())
```

Clearly, the indicators that measure income directly have a much larger influence on our wealth index than the others. Each 1-point increase in household income (`q10new`) increases the wealth index by 0.13, while the increases based on possessions average to about 0.004. Having a microwave oven (`r7`) increases a person's wealth index more than having a cell phone (`r4a`). Even poor people have cell phones, while microwaves tend to show a large difference between rich and poor households. 

How do we know whether this is really a good composite index? We've seen a few good signs already -- it captures most of the variance in the underlying indicators, it's robust to random variations in multiple imputation, and it's fairly nicely-distributed. The other thing to look for is how well it does at predicting the values of the individual variables -- a good wealth index should do a reasonable job of predicting how much income someone has and which things they own.

First, let's look at income (`q10new`):

```{r}
q10new <- data.frame(q=my_data$q10new,w=wealth$w)
q10new <- na.omit(q10new)
my_lm <- lm(data=q10new, q ~ w)
summary(my_lm)
ggplot(q10new,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=14,hjust=0,vjust=0,color='royalblue') +
  ylab('q10new') +
  xlab('Wealth index') +
  theme(text=element_text(size=20)) 
```

Now, what about microwave ownership (`r7`)?

```{r}
r7 <- data.frame(r=my_data$r7,w=wealth$w)
r7 <- na.omit(r7)
my_glm <- glm(data=r7, r ~ w, family=binomial(logit))
summary(my_glm)
ggplot(r7,aes(x=w,y=r)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0.1,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('r7') +
  xlab('Wealth index') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
```

This fit isn't quite as pretty as `q10new` was, but the summary from the logistic regression calculation tells us that our wealth index has a highly-significant impact on microwave oven ownership. We can also see on the plot that the non-owners (`r7` = 0) are bunched up at the low-wealth end of the spectrum, as we'd expect. It should be easy to modify these plots for some of the other variables; you can see which ones are well-predicted by our wealth index and which ones might not be as much.

We can test this more rigorously using 2-sample t-tests:

```{r}
bin_cor <- function(var) {
  tt <- t.test(all_pc1$norm[var==min(var,na.rm=TRUE)],
               all_pc1$norm[var==max(var,na.rm=TRUE)])
  tt$p.value
}

bin_vars <- c('r3','r4','r4a','r6','r7','r8','r12','r14','r15','r18','r1',
              'r16','r26')
sapply(bin_vars,function(x) bin_cor(my_data[,x]))
```

All of our p-values on logistic regressions are highly significant, meaning that our wealth index has a strong influence on all of these wealth-related variables. This is what we would expect! Notice that the smallest p-values (i.e. the highest significance) are for variables like `r14` and `r18` where the influence on the wealth index was higher. This is also what we would expect; variables like `r8` are still significant but not as strong.

Finally, check these values against the comments in `make_indices.R` to be sure we're calculating the same index:

```{r}
quantile(all_pc1$norm)
```